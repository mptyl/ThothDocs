# Installazione di ThothAI - attività preliminari
**ThothAI** può essere installato sia come container `Docker`, per poter lavorare in un ambiente di produzione isolato e facilmente gestibile, sia in locale, per operare in un contesto di `'development'` che permetta agevolmente di realizzare e testare eventuali personalizzazioni.

Prerequisiti consigliati per lo sviluppo locale:

- `Python 3.13` o superiore, gestito con `uv` (per ambienti e dipendenze riproducibili)
- `Node.js`/`npm` per frontend e servizi Node
- `Docker` per il servizio Qdrant (vector DB) quando avviato in locale

Per l'installazione in Docker è sufficiente avere Docker (e, se previsto, `docker-compose`).

!!! note "Installazione di Python"

    Le procedure di installazione di Python sono al di fuori dell'ambito di questo documento.
    Andare sul sito di [Python](https://www.python.org/) per acquisire le informazioni necessarie a installare o aggiornare Python, se non è già stato fatto.

## 1 - Attività preliminare - clonazione del repository

L'attività di installazione richiede prima di tutto l'acquisizione dei sorgenti del progetto. 
**ThothAI** è composto da un singolo repository che contiene sia il backend che il frontend.

Da linea di comando posizionarsi dove si preferisce e clonare il repository:

```bash
git clone https://github.com/mptyl/Thoth.git ThothAI
cd ThothAI
```

Dopo la clonazione, la struttura del progetto sarà simile a questa:

```
ThothAI/
├── backend/                # Applicazione Django (backend)
├── frontend/               # Applicazione Next.js (frontend)
├── docker/                 # File di configurazione Docker
├── scripts/                # Script di installazione e configurazione
├── config.yml              # Template di configurazione
├── .env.local.template     # Template delle variabili d'ambiente
└── ...
```

## 2 - Attività preliminare - configurazione di base

### 2.1 - Preparazione della configurazione per lo sviluppo locale {#preparazione-configurazione}

Per l'avvio in locale, il file di configurazione principale è `.env.local`, creato a partire da `.env.local.template` alla radice del progetto. Sarà caricato automaticamente dallo script `start-all.sh` che provvede anche a rimuovere un'eventuale variabile `PORT` generica per evitare conflitti con le porte specifiche dei servizi.

```bash
cp .env.local.template .env.local
```

Per l'esecuzione locale non è necessario alcun file YAML: basta `.env.local`.
Per il deploy Docker fare riferimento a `config.yml` e alla relativa documentazione.

Elementi da configurare in `.env.local` (minimo indispensabile):

- **LLM backend**: provider e modello per il backend (`BACKEND_AI_PROVIDER`, `BACKEND_AI_MODEL`), con relative API key del provider scelto
- **Sicurezza**: `DJANGO_SECRET_KEY` e `DJANGO_API_KEY`
- **Porte locali**: se diverse dai default
  - `FRONTEND_PORT` (default 3200)
  - `BACKEND_PORT` (default 8200)
  - `SQL_GENERATOR_PORT` (default 8180)
  - `MERMAID_SERVICE_PORT` (default 8003)
- **Servizi ausiliari**: opzionale `MERMAID_SERVICE_URL` (se non impostata, lo script usa `http://localhost:${MERMAID_SERVICE_PORT}`)

Il servizio Qdrant viene avviato tramite Docker sulla porta host `6334` (mappata sulla `6333` interna al container) se non è già in esecuzione.

!!! note "Provider LLM consigliato per iniziare"

    Per una rapida prova di ThothAI, si consiglia di utilizzare **OpenRouter** che fornisce accesso a centinaia di modelli LLM con una singola API key e include anche modelli gratuiti. L'installazione Docker di ThothAI prevede lla creazione di un ambiente demo già preconfigurato per utilizzare OpenRouter come provider e CaliforniaSchools come database su cui esercitarsi. 

#### Esempio: `.env.local.template`

```env
# Copyright (c) 2025 Marco Pancotti
# This file is part of Thoth and is released under the Apache License 2.0.
# See the LICENSE.md file in the project root for full license information.

# === THOTH AI - LOCAL DEVELOPMENT ENVIRONMENT TEMPLATE ===
# Copy this file to .env.local and fill in your API keys

# --- REQUIRED: LLM API Keys (at least one) ---
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here
GEMINI_API_KEY=your-gemini-key-here

# --- REQUIRED: Embedding Service ---
EMBEDDING_PROVIDER=cohere
EMBEDDING_API_KEY=your-embedding-key-here
EMBEDDING_MODEL=embed-multilingual-v3.0

# --- Backend Default LLM (Required) ---
# Provider must be one of: openai, anthropic, gemini, mistral, deepseek, openrouter, ollama, lm_studio, groq
BACKEND_AI_PROVIDER=openrouter
# Model identifier for the chosen provider (prefix with vendor when needed, e.g. openrouter: vendor/model)
BACKEND_AI_MODEL=openai/gpt-4o-mini

# --- OPTIONAL: Additional LLM Providers ---
MISTRAL_API_KEY=
DEEPSEEK_API_KEY=
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
OPENROUTER_API_KEY=
OPENROUTER_API_BASE=https://openrouter.ai/api/v1
GROQ_API_KEY=

# --- OPTIONAL: Local Model Endpoints ---
OLLAMA_API_BASE=http://127.0.0.1:11434
LM_STUDIO_API_BASE=http://localhost:1234

# --- Local Development Ports ---
FRONTEND_PORT=3200
BACKEND_PORT=8200
SQL_GENERATOR_PORT=8180
MERMAID_SERVICE_PORT=8003
QDRANT_PORT=6334

# --- Local Service URLs ---
MERMAID_SERVICE_URL=http://localhost:8003

# --- Local Paths ---
EXPORTS_DIR=./exports
LOGS_DIR=./logs
DB_ROOT_PATH=./data
DB_NAME_LOCAL=db.sqlite3

# --- SQL Generator Dev Flags ---
# SQLGEN_BYPASS_EVALUATION=false

# --- Logging Configuration ---
BACKEND_LOGGING_LEVEL=INFO
FRONTEND_LOGGING_LEVEL=INFO
DEBUG=True

# --- OPTIONAL: Monitoring ---
LOGFIRE_TOKEN=

# --- Security (auto-generated if not provided) ---
SECRET_KEY=change-this-to-a-secure-random-string
NEXTAUTH_SECRET=change-this-to-another-secure-random-string
DJANGO_API_KEY=generate-a-secure-api-key-here

# --- RelevanceGuard Settings (SQL Generator) ---
RELEVANCE_STRICT_MIN_SCORE=0.75
RELEVANCE_WEAK_MIN_SCORE=0.45
RELEVANCE_DROP_BELOW=0.30
RELEVANCE_W_BM25=0.60
RELEVANCE_W_STRUCT=0.40
RELEVANCE_USE_RRF=false
RELEVANCE_LOG_JSONL=true

STRICT_FAILS_REQUIRED=2
```

### 2.2 - Preparazione delle variabili d'ambiente (solo per sviluppo locale)

Se prevedete di eseguire ThothAI in modalità sviluppo locale (non solo Docker), dovrete anche configurare il file delle variabili d'ambiente:

```bash
cp .env.local.template .env.local
```

Il file `.env.local` contiene:
- Le chiavi API per il provider LLM scelto e i relativi parametri del backend AI
- Le impostazioni del servizio di embedding (se previste dalla vostra configurazione)
- Le porte per l'esecuzione locale dei servizi (`FRONTEND_PORT`, `BACKEND_PORT`, `SQL_GENERATOR_PORT`, `MERMAID_SERVICE_PORT`)
- Le impostazioni di sicurezza (`DJANGO_SECRET_KEY`, `DJANGO_API_KEY`)
- Eventuali URL di servizi ausiliari (`MERMAID_SERVICE_URL`), se personalizzati

!!! warning "Importante"

    Le chiavi API e i secret nel file `.env.local` sono sensibili e non devono essere condivisi o committati nel repository.

## 3 - Attività preliminare - acquisizione delle API Keys

Prima di procedere con l'installazione vera e propria, è necessario dotarsi delle API Keys per:

### 3.1 - I servizi di generazione tramite LLM

**ThothAI** è predisposto per potersi collegare ai seguenti fornitori di API LLM:

* OpenAI 
* Gemini (di Google)
* Anthropic 
* Mistral
* DeepSeek
* LMStudio
* Ollama
* OpenRouter (che fa da proxy a centinaia di provider)

Ogni fornitore di API, a sua volta, permette di usare diversi modelli, che andranno specificati nel setup dell'applicazione.

In fase di configurazione occorre stabilire quali provider si desidera utilizzare. Per ognuno di essi è necessario procurarsi una API Key.
Se si utilizza Ollama o LMStudio in locale, ovviamente, non è necessaria alcuna API Key, ma solo indicare l'IP del server utilizzato se diverso da quello standard. 

Per procurarsi l'API Key occorre seguire le procedure previste dal provider.

!!! note "Assegnazione di una API Key"

    Le procedure di assegnazione di una API Key sono più o meno le stesse per ogni fornitore. 
    Creare delle API Key con il nome che preferite, come ad esempio "ThothKey" o simile, per ogni fornitore che si desidera utilizzare. IQueste chiavi devono essere indicate nel file di configurazione `config.yml` se si vuole utilizzare Docker, altrimenti nel file di configurazione .env.local

Se si usa OpenRouter, con una sola API Key si potrà accedere a una lunga lista di LLM, aventi dimensioni e costi molto variabili (alcuni modelli sono resi disponibili addirittura gratuitamente). Andare sul sito di [OpenRouter](https://openrouter.ai/) per ulteriori dettagli. 

Tramite `OpenRouter` si possono utilizzare modelli di provider non previsti dalla lista precedente, in quanto OpenRouter provvede a esporre sempre la stessa interfaccia, compatibile con l'interfaccia di OpenAI, utilizzabile per tutti i modelli che supporta.  

I valori di default impostati in ThothAI prevedono che tutti gli Agent che svolgono le varie fasi del processo usino un modello fornito da OpenRouter. 

L'utente può ovviamente cambiare questo setup (si vedrà più avanti come), ma, se si vuole provare rapidamente ThothAI, l'ideale è iniziare con l'acquisto di 5 o 10 dollari di servizi OpenRouter e lasciare le impostazioni di default che vengono impostate in fase di installazione. 

Dai nostri test, utilizzando la configurazione di default che prevede un largo uso di modelli economici nelle fasi meno critiche del processo, ogni esecuzione ha un costo variabile tra 2 e 5 centesimi di dollaro, in funzione del numero di agenti che si vuole attivare in parallelo (più agenti, più probabilità di avere un buon SQL, più costo).
Per cui, con una decina di dollari, si possono fare da 200 a 500 esecuzioni.

### 3.2 - Il servizio Logfire

[Logfire](https://pydantic.dev/logfire) è un servizio messo a disposizione da Pydantic per tracciare l'attività di applicazioni Python. Fino a 10 milioni di messaggi al mese è un servizio gratuito.  

ThothAI produce un log delle sue attività contemporaneamente su file, su console e su Logfire. Il log su Logfire persiste per circa 30 giorni e fornisce un elevato livello di dettaglio sulle operazioni registrate.

Su Logfire non vengono mai inviati dati sul contenuto dei database interrogati, ma, se non si vuole utilizzare il servizio, basta lasciare vuota la chiave e Logfire non verrà utilizzato. In questo caso rimarranno solo i file di log salvati in locale [(vedi logs)](../4-user_manual/4.3-logging/4.3.2-log_management.md). Non si avrà però lo stesso livello di granularità e di insight fornita da Logfire.

Se si vuole usare Logfire è necessario quindi andare su [Logfire](https://pydantic.dev/logfire) e crearsi una API Key. Scegliere un server europeo se si sta operando da un paese europeo per avere migliori performance. Salvare l'URL del server per le future consultazioni. 

!!! note "Il logging di un LLM"

    Loggare le attività effettuate da un LLM è un'attività piuttosto complessa. Con Logfire si può facilmente verificare il testo del prompt ricevuto dal LLM, l'eventuale attivazione di tool da parte dell'Agent in esecuzione e l'output generato, con abbondanza di dettagli.
    
    Se si vuole controllare al meglio l'azione di ThothAI è opportuno attivare Logfire. Il servizio è attivabile anche in locale, fatte le opportune attività di setup, per cui eventuali problematiche sulla privacy possono essere comunque superate. Per dettagli consultare la documentazione di Logfire. 

## 4 - Attività preliminare - generazione delle chiavi di sicurezza

!!! info "Nota importante"

    **Questa sezione è obbligatoria solo per l'avvio in locale.** Se prevedete di utilizzare Docker, la procedura di installazione genererà automaticamente le chiavi di sicurezza necessarie. Potete saltare questa sezione e passare direttamente alla sezione 5.

### 4.1 - La generazione della Django SECRET_KEY

L'applicazione di backend Thoth è basata su Django, un framework molto utilizzato in ambito Python. Il setup di Django richiede che vengano generate due key da impostare nel file di configurazione.

La SECRET_KEY di Django è una componente fondamentale per la sicurezza dell'applicazione web. Serve principalmente a:

* Fornire firme crittografiche per proteggere dati e sessioni da manomissioni.
* Proteggere contro attacchi CSRF (Cross-Site Request Forgery) generando token unici per ogni sessione utente.
* Firmare e verificare i cookie di sessione, assicurando che i dati di sessione non vengano alterati da terzi.
* Contribuire alla generazione di hash sicuri per le password, aumentando la sicurezza degli account utente.
* Creare firme digitali per autenticare dati come token di autenticazione o parametri URL.

!!! note "La generazione di una SECRET_KEY per Django"

    Per generare una nuova SECRET_KEY di Django si può utilizzare il generatore online messo a disposizione da Djecrety all'indirizzo [https://djecrety.ir/](https://djecrety.ir/)

### 4.2 - La generazione della DJANGO_API_KEY

Per generare una chiave API sicura, da usare nella comunicazione tra frontend e backend, utilizzare questo piccolo snippet Python:

```bash
python3 -c "import secrets; print(secrets.token_urlsafe(32))"
```

## 5 - Prossimi passi

Una volta completate queste attività preliminari, si può procedere con:

* [Installazione in locale](./2.2-local.md)
* [Quickstart](../3-quickstart/3.1-quick_setup.md)
