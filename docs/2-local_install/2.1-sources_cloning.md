# Installazione di ThothAI - attività preliminari
**ThothAI** può essere installato sia come container `Docker`, per poter lavorare in un ambiente di produzione isolato e facilmente gestibile, sia in locale, per operare in un contesto di `'development'` che permetta agevolmente di realizzare e testare eventuali personalizzazioni.

L'unico prerequisito per l'installazione in locale è la disponibilità di `Python 3.13` o superiore. Per l'installazione in Docker non ci sono requisiti particolari oltre a quello di avere Docker ed il client `docker-compose`.

!!! note "Installazione di Python"

    Le procedure di installazione di Python sono al di fuori dell'ambito di questo documento.
    Andare sul sito di [Python](https://www.python.org/) per acquisire le informazioni necessarie a installare o aggiornare Python, se non è già stato fatto.

## 1 - Attività preliminare - clonazione del repository

L'attività di installazione richiede prima di tutto l'acquisizione dei sorgenti del progetto. 
**ThothAI** è composto da un singolo repository che contiene sia il backend che il frontend.

Da linea di comando posizionarsi dove si preferisce e clonare il repository:

```bash
git clone https://github.com/mptyl/Thoth.git ThothAI
cd ThothAI
```

Dopo la clonazione, la struttura del progetto sarà simile a questa:

```
ThothAI/
├── backend/                # Applicazione Django (backend)
├── frontend/               # Applicazione Next.js (frontend)
├── docker/                 # File di configurazione Docker
├── scripts/                # Script di installazione e configurazione
├── config.yml              # Template di configurazione
├── .env.local.template     # Template delle variabili d'ambiente
└── ...
```

## 2 - Attività preliminare - configurazione di base

### 2.1 - Preparazione del file di configurazione {#preparazione-configurazione}

Il primo passo **obbligatorio** per l'installazione di ThothAI è creare il file di configurazione personale partendo dal template fornito:

```bash
cp config.yml config.yml.local
```

Il file `config.yml.local` contiene tutte le impostazioni necessarie per il funzionamento di ThothAI. Dovrete configurare:

- **Provider AI**: Scegliere almeno un provider LLM (OpenAI, Anthropic, Gemini, Mistral, DeepSeek, OpenRouter, Ollama, LM Studio, Groq)
- **Servizio di embedding**: Configurare il servizio per la ricerca semantica (OpenAI, Mistral, o Cohere)
- **Database supportati**: Abilitare i driver per i database che si intende utilizzare
- **Credenziali admin**: Impostare username/password per l'accesso amministrativo dell'utente admin
- **Credenziali demo**: Impostare username/password per l'accesso dell'utente demo utilizzabile immediatamente per provare il software senza dover configurare nulla
- **Porte dei servizi**: Configurare le porte per i vari componenti - se quelle di default sono in conflitto con servizi già in attività sulle stesse porte
- **Monitoraggio**: Configurare Logfire per il monitoraggio dell'applicazione (vedi [monitoring](../4-user_manual/4.4-logging/4.4.1-logfire.md)
- **Database supportati**: Indcare quali database sono supportati. Al momento è possibile utilizzare Mariadb, PostgreSQL, SQLite e SqlServer.

!!! note "Provider LLM consigliato per iniziare"

    Per una rapida prova di ThothAI, si consiglia di utilizzare **OpenRouter** che fornisce accesso a centinaia di modelli LLM con una singola API key e include anche modelli gratuiti. L'installazione Docker di ThothAI prevede lla creazione di un ambiente demo già preconfigurato per utilizzare OpenRouter come provider e CaliforniaSchools come database su cui esercitarsi. Vedi [qui](../test-database.md) per maggiori dettagli.

#### 2.1.1 - Parametri correnti dal file `config.yml`

Di seguito i parametri attualmente impostati nel file di configurazione principale `config.yml` alla radice del progetto (`ThothAI/config.yml`). Usateli come riferimento durante la preparazione di `config.yml.local`.

```yaml
version: "1.0"

ai_providers:
  openai:
    enabled: false
    api_key: ""
  anthropic:
    enabled: false
    api_key: ""
  gemini:
    enabled: false
    api_key: ""
  mistral:
    enabled: false
    api_key: ""
  deepseek:
    enabled: false
    api_key: ""
    api_base: "https://api.deepseek.com/v1"
  openrouter:
    enabled: true
    api_key: ""
    api_base: "https://openrouter.ai/api/v1"
  ollama:
    enabled: false
    api_base: "http://127.0.0.1:11434"
  lm_studio:
    enabled: false
    api_base: "http://localhost:1234"
  groq:
    enabled: false
    api_key: ""

embedding:
  provider: "openai"
  api_key: ""
  model: "text-embedding-3-small"

backend_ai_model:
  ai_provider: "openrouter"
  ai_model: "google/gemini-2.5-flash"

databases:
  sqlite: true
  postgresql: true
  mysql: false
  mariadb: true
  sqlserver: true

admin:
  email: ""
  username: "admin"
  password: "admin123"

demo:
  email: ""
  username: "demo"
  password: "demo1234"

monitoring:
  enabled: true
  logfire_token: ""

ports:
  frontend: 3040
  backend: 8000
  sql_generator: 8020
  nginx: 8040
  qdrant: 6333

docker:
  network_name: "thoth-network"
  compose_file: "docker-compose.yml"
  build_cache: true

development:
  debug: false
  log_level: "INFO"
  hot_reload: true

relevance_guard:
  strict_min_score: 0.75
  weak_min_score: 0.45
  drop_below: 0.30
  w_bm25: 0.60
  w_struct: 0.40
  use_rrf: false
  strict_fails_required: 2
```

Nota: i campi `api_key` sono volutamente vuoti nel file di esempio. Inserite le vostre chiavi dove appropriato oppure utilizzate il file `.env.local` in modalità sviluppo locale.

### 2.2 - Preparazione delle variabili d'ambiente (solo per sviluppo locale)

Se prevedete di eseguire ThothAI in modalità sviluppo locale (non solo Docker), dovrete anche configurare il file delle variabili d'ambiente:

```bash
cp .env.local.template .env.local
```

Il file `.env.local` contiene:
- Le chiavi API per i provider LLM configurati
- Le impostazioni del servizio di embedding
- Le porte per l'esecuzione locale
- I percorsi locali per database e log
- Le impostazioni di sicurezza (SECRET_KEY, DJANGO_API_KEY)

!!! warning "Importante"

    Le chiavi API e i secret nel file `.env.local` sono sensibili e non devono essere condivisi o committati nel repository.

## 3 - Attività preliminare - acquisizione delle API Keys

Prima di procedere con l'installazione vera e propria, è necessario dotarsi delle API Keys per:

### 3.1 - I servizi di generazione tramite LLM

**ThothAI** è predisposto per potersi collegare ai seguenti fornitori di API LLM:

* OpenAI 
* Gemini (di Google)
* Anthropic 
* Mistral
* DeepSeek
* LMStudio
* Ollama
* OpenRouter (che fa da proxy a centinaia di provider)

Ogni fornitore di API, a sua volta, permette di usare diversi modelli, che andranno specificati nel setup dell'applicazione.

In fase di configurazione occorre stabilire quali provider si desidera utilizzare. Per ognuno di essi è necessario procurarsi una API Key.
Se si utilizza Ollama o LMStudio in locale, ovviamente, non è necessaria alcuna API Key, ma solo indicare l'IP del server utilizzato se diverso da quello standard. 

Per procurarsi l'API Key occorre seguire le procedure previste dal provider.

!!! note "Assegnazione di una API Key"

    Le procedure di assegnazione di una API Key sono più o meno le stesse per ogni fornitore. 
    Creare delle API Key con il nome che preferite, come ad esempio "ThothKey" o simile, per ogni fornitore che si desidera utilizzare. IQueste chiavi devono essere indicate nel file di configurazione `config.yml` se si vuole utilizzare Docker, altrimenti nel file di configurazione .env.local

Se si usa OpenRouter, con una sola API Key si potrà accedere a una lunga lista di LLM, aventi dimensioni e costi molto variabili (alcuni modelli sono resi disponibili addirittura gratuitamente). Andare sul sito di [OpenRouter](https://openrouter.ai/) per ulteriori dettagli. 

Tramite `OpenRouter` si possono utilizzare modelli di provider non previsti dalla lista precedente, in quanto OpenRouter provvede a esporre sempre la stessa interfaccia, compatibile con l'interfaccia di OpenAI, utilizzabile per tutti i modelli che supporta.  

I valori di default impostati in ThothAI prevedono che tutti gli Agent che svolgono le varie fasi del processo usino un modello fornito da OpenRouter. 

L'utente può ovviamente cambiare questo setup (si vedrà più avanti come), ma, se si vuole provare rapidamente ThothAI, l'ideale è iniziare con l'acquisto di 5 o 10 dollari di servizi OpenRouter e lasciare le impostazioni di default che vengono impostate in fase di installazione. 

Dai nostri test, utilizzando la configurazione di default che prevede un largo uso di modelli economici nelle fasi meno critiche del processo, ogni esecuzione ha un costo variabile tra 2 e 5 centesimi di dollaro, in funzione del numero di agenti che si vuole attivare in parallelo (più agenti, più probabilità di avere un buon SQL, più costo).
Per cui, con una decina di dollari, si possono fare da 200 a 500 esecuzioni.

### 3.2 - Il servizio Logfire

[Logfire](https://pydantic.dev/logfire) è un servizio messo a disposizione da Pydantic per tracciare l'attività di applicazioni Python. Fino a 10 milioni di messaggi al mese è un servizio gratuito.  

ThothAI produce un log delle sue attività contemporaneamente su file, su console e su Logfire. Il log su Logfire persiste per circa 30 giorni e fornisce un elevato livello di dettaglio sulle operazioni registrate.

Su Logfire non vengono mai inviati dati sul contenuto dei database interrogati, ma, se non si vuole utilizzare il servizio, basta lasciare vuota la chiave e Logfire non verrà utilizzato. In questo caso rimarranno solo i file di log salvati in locale [(vedi logs)](../4-user_manual/4.4-logging/4.4.2-log_management.md). Non si avrà però lo stesso livello di granularità e di insight fornita da Logfire.

Se si vuole usare Logfire è necessario quindi andare su [Logfire](https://pydantic.dev/logfire) e crearsi una API Key. Scegliere un server europeo se si sta operando da un paese europeo per avere migliori performance. Salvare l'URL del server per le future consultazioni. 

!!! note "Il logging di un LLM"

    Loggare le attività effettuate da un LLM è un'attività piuttosto complessa. Con Logfire si può facilmente verificare il testo del prompt ricevuto dal LLM, l'eventuale attivazione di tool da parte dell'Agent in esecuzione e l'output generato, con abbondanza di dettagli.
    
    Se si vuole controllare al meglio l'azione di ThothAI è opportuno attivare Logfire. Il servizio è attivabile anche in locale, fatte le opportune attività di setup, per cui eventuali problematiche sulla privacy possono essere comunque superate. Per dettagli consultare la documentazione di Logfire. 

## 4 - Attività preliminare - generazione delle chiavi di sicurezza

!!! info "Nota importante"

    **Questa sezione è obbligatoria solo per l'avvio in locale.** Se prevedete di utilizzare Docker, la procedura di installazione genererà automaticamente le chiavi di sicurezza necessarie. Potete saltare questa sezione e passare direttamente alla sezione 5.

### 4.1 - La generazione della Django SECRET_KEY

L'applicazione di backend Thoth è basata su Django, un framework molto utilizzato in ambito Python. Il setup di Django richiede che vengano generate due key da impostare nel file di configurazione.

La SECRET_KEY di Django è una componente fondamentale per la sicurezza dell'applicazione web. Serve principalmente a:

* Fornire firme crittografiche per proteggere dati e sessioni da manomissioni.
* Proteggere contro attacchi CSRF (Cross-Site Request Forgery) generando token unici per ogni sessione utente.
* Firmare e verificare i cookie di sessione, assicurando che i dati di sessione non vengano alterati da terzi.
* Contribuire alla generazione di hash sicuri per le password, aumentando la sicurezza degli account utente.
* Creare firme digitali per autenticare dati come token di autenticazione o parametri URL.

!!! note "La generazione di una SECRET_KEY per Django"

    Per generare una nuova SECRET_KEY di Django si può utilizzare il generatore online messo a disposizione da Djecrety all'indirizzo [https://djecrety.ir/](https://djecrety.ir/)

### 4.2 - La generazione della DJANGO_API_KEY

Per generare una chiave API sicura, da usare nella comunicazione tra frontend e backend, utilizzare questo piccolo snippet Python:

```bash
python3 -c "import secrets; print(secrets.token_urlsafe(32))"
```

## 5 - Prossimi passi

Una volta completate queste attività preliminari, si può procedere con:

* [Installazione in locale](./1.4-local.md)
* [Installazione assistita su Docker](../1-docker_install/1.2-docker_assisted.md)
* [Installazione manuale su Docker](../1-docker_install/1.3-docker_manual.md)
