# Installazione di ThothAI - attività preliminari
**ThothAI** può essere installato sia come container `Docker`, per poter lavorare in un ambiente di produzione isolato e facilmente gestibile, 
sia in locale, per operare in un contesto di `'development'` che permetta agevolmente di realizzare e testare eventuali personalizzazioni.

L'unico prerequisito è la disponibilità di `Python 3.13` o superiore.

!!! note "Installazione di Python"

    Le procedure di installazione di Python sono al di fuori dell'ambito di questo documento.
    Andare sul sito di [Python](https://www.python.org/) per acquisire le informazioni necessarie a installare o aggiornare Python, se non è già stato fatto.

## 1 - Attività preliminare - clonazione del repository

L'attività di installazione richiede prima di tutto l'acquisizione dei sorgenti del progetto. **ThothAI** è composto da un singolo repository che contiene sia il backend che il frontend.

Da linea di comando posizionarsi dove si preferisce e clonare il repository:

```bash
git clone https://github.com/mptyl/Thoth.git ThothAI
cd ThothAI
```

Dopo la clonazione, la struttura del progetto sarà simile a questa:

```
ThothAI/
├── backend/           # Applicazione Django (backend)
├── frontend/          # Applicazione Next.js (frontend)
├── docker/           # File di configurazione Docker
├── scripts/          # Script di installazione e configurazione
├── config.yml        # Template di configurazione
├── .env.local.template # Template delle variabili d'ambiente
└── ...
```

## 2 - Attività preliminare - configurazione di base

### 2.1 - Preparazione del file di configurazione {#preparazione-configurazione}

Il primo passo obbligatorio è creare il file di configurazione personale partendo dal template fornito:

```bash
cp config.yml config.yml.local
```

Il file `config.yml.local` contiene tutte le impostazioni necessarie per il funzionamento di ThothAI. Dovrete configurare:

- **Provider AI**: Scegliere almeno un provider LLM (OpenAI, Anthropic, Gemini, Mistral, DeepSeek, OpenRouter, Ollama, LM Studio, Groq)
- **Servizio di embedding**: Configurare il servizio per la ricerca semantica (OpenAI, Mistral, o Cohere)
- **Database supportati**: Abilitare i driver per i database che si intende utilizzare
- **Credenziali admin**: Impostare username/password per l'accesso amministrativo
- **Porte dei servizi**: Configurare le porte per i vari componenti (se quelle di default confliggono)
- **Monitoraggio**: Configurare Logfire per il monitoraggio dell'applicazione

!!! note "Provider LLM consigliato per iniziare"

    Per una rapida prova di ThothAI, si consiglia di utilizzare **OpenRouter** che fornisce accesso a centinaia di modelli LLM con una singola API key e include anche modelli gratuiti.

### 2.2 - Preparazione delle variabili d'ambiente (solo per sviluppo locale)

Se prevedete di eseguire ThothAI in modalità sviluppo locale (non solo Docker), dovrete anche configurare il file delle variabili d'ambiente:

```bash
cp .env.local.template .env.local
```

Il file `.env.local` contiene:
- Le chiavi API per i provider LLM configurati
- Le impostazioni del servizio di embedding
- Le porte per l'esecuzione locale
- I percorsi locali per database e log
- Le impostazioni di sicurezza (SECRET_KEY, DJANGO_API_KEY)

!!! warning "Importante"

    Le chiavi API e i secret nel file `.env.local` sono sensibili e non devono essere condivisi o committati nel repository.

## 3 - Attività preliminare - acquisizione delle API Keys

Prima di procedere con l'installazione vera e propria, è necessario dotarsi delle API Keys per:

### 3.1 - I servizi di generazione tramite LLM

**ThothAI** è predisposto per potersi collegare ai seguenti fornitori di API LLM:

* OpenAI 
* Gemini (di Google)
* Anthropic 
* Mistral
* DeepSeek
* LMStudio
* Ollama
* OpenRouter (che fa da proxy a centinaia di provider)

Ogni fornitore di API, a sua volta, permette di usare diversi modelli, che andranno specificati nel setup dell'applicazione.

In fase di configurazione occorre stabilire quali provider si desidera utilizzare. Per ognuno di essi è necessario procurarsi una API Key.
Se si utilizza Ollama o LMStudio in locale, ovviamente, non è necessaria alcuna API Key, ma solo indicare l'IP del server utilizzato. 

Per procurarsi l'API Key occorre seguire le procedure previste dal provider.

!!! note "Assegnazione di una API Key"

    Le procedure di assegnazione di una API Key sono più o meno le stesse per ogni fornitore. 
    Creare delle API Key con il nome che preferite, come ad esempio "ThothKey" o simile, per ogni fornitore che si desidera utilizzare. In seguito, si indicherà dove dovranno essere utilizzate.

Se si usa OpenRouter, con una sola API Key si potrà accedere a una lunga lista di LLM, aventi dimensioni e costi molto variabili (alcuni modelli sono resi disponibili addirittura gratuitamente). Andare sul sito di [OpenRouter](https://openrouter.ai/) per ulteriori dettagli. Tramite `OpenRouter` si possono utilizzare modelli di provider non previsti dalla lista precedente, in quanto OpenRouter provvede a esporre sempre la stessa interfaccia, compatibile con OpenAI, utilizzabile per tutti i modelli che supporta.  

I valori di default impostati in Thoth prevedono che tutti gli Agent che svolgono le varie fasi del processo usino LLM forniti da OpenRouter. 
L'utente può ovviamente cambiare questo setup (si vedrà più avanti come), ma, se si vuole provare rapidamente ThothAI, l'ideale è iniziare con l'acquisto di 5 o 10 dollari di servizi OpenRouter e lasciare le impostazioni di default che vengono impostate in fase di installazione. 

Dai nostri test, utilizzando la configurazione di default che prevede un largo uso di modelli economici nelle fasi meno critiche del processo, ogni esecuzione ha un costo variabile tra 2 e 5 centesimi di dollaro, in funzione del numero di agenti che si vuole attivare in parallelo (più agenti, più probabilità di avere un buon SQL).
Per cui, con una decina di dollari, si possono fare da 200 a 500 esecuzioni.

### 3.2 - Il servizio Logfire

[Logfire](https://pydantic.dev/logfire) è un servizio messo a disposizione da Pydantic per tracciare l'attività di applicazioni Python. Fino a 10 milioni di messaggi al mese è un servizio gratuito.  

ThothAI produce un log delle sue attività contemporaneamente su console e su Logfire. Il log su Logfire persiste per circa 30 giorni e fornisce un elevato livello di dettaglio sulle operazioni registrate.

Su Logfire non vengono mai inviati dati sul contenuto dei database interrogati, ma, se non si vuole utilizzare il servizio, basta lasciare vuota la chiave e Logfire non verrà utilizzato. In questo caso rimarranno solo i file di log salvati in locale [(vedi logs)](../3-user_manual/3.4-logging/3.4.2-log_management.md).

Se si vuole usare Logfire è necessario quindi andare su [Logfire](https://pydantic.dev/logfire) e crearsi una API Key. Scegliere un server europeo per avere migliori performance. Salvare l'URL del server europeo per le future consultazioni. 

!!! note "Il logging di un LLM"

    Loggare le attività effettuate da un LLM è un'attività piuttosto complessa. Con Logfire si può facilmente verificare il testo del prompt ricevuto dal LLM, l'eventuale attivazione di tool da parte dell'Agent in esecuzione e l'output generato, con abbondanza di dettagli.
    
    Se si vuole controllare al meglio l'azione di ThothAI è opportuno attivare Logfire. Il servizio è attivabile anche in locale, fatte le opportune attività di setup, per cui eventuali problematiche sulla privacy possono essere comunque superate. Per dettagli consultare la documentazione di Logfire. 

## 4 - Attività preliminare - generazione delle chiavi di sicurezza

!!! info "Nota importante"

    **Questa sezione è obbligatoria solo per l'avvio in locale.** Se prevedete di utilizzare Docker, la procedura di installazione genererà automaticamente le chiavi di sicurezza necessarie. Potete saltare questa sezione e passare direttamente alla sezione 5.

### 4.1 - La generazione della Django SECRET_KEY

L'applicazione di backend Thoth è basata su Django, un framework molto utilizzato in ambito Python. Il setup di Django richiede che vengano generate due key da impostare nel file di configurazione.

La SECRET_KEY di Django è una componente fondamentale per la sicurezza dell'applicazione web. Serve principalmente a:

* Fornire firme crittografiche per proteggere dati e sessioni da manomissioni.
* Proteggere contro attacchi CSRF (Cross-Site Request Forgery) generando token unici per ogni sessione utente.
* Firmare e verificare i cookie di sessione, assicurando che i dati di sessione non vengano alterati da terzi.
* Contribuire alla generazione di hash sicuri per le password, aumentando la sicurezza degli account utente.
* Creare firme digitali per autenticare dati come token di autenticazione o parametri URL.

!!! note "La generazione di una SECRET_KEY per Django"

    Per generare una nuova SECRET_KEY di Django si può utilizzare il generatore online messo a disposizione da Djecrety all'indirizzo [https://djecrety.ir/](https://djecrety.ir/)

### 4.2 - La generazione della DJANGO_API_KEY

Per generare una chiave API sicura, da usare nella comunicazione tra frontend e backend, utilizzare questo piccolo snippet Python:

```bash
python3 -c "import secrets; print(secrets.token_urlsafe(32))"
```

## 5 - Prossimi passi

Una volta completate queste attività preliminari, si può procedere con:

* [Installazione assistita su Docker](../1-install/1.2-docker_assisted.md)
* [Installazione manuale su Docker](../1-install/1.3-docker_manual.md)
* [Installazione in locale](../1-install/1.4-local.md)

Ogni modalità di installazione avrà le sue specificità, ma tutte partiranno dalla configurazione preparata in questa fase.
